{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16b7819",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"> **Air Quality** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 04: Batch Inference</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "\n",
    "1. Download model and batch inference data\n",
    "2. Make predictions, generate PNG for forecast\n",
    "3. Store predictions in a monitoring feature group adn generate PNG for hindcast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a84ee9",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb904bb-a8c4-45d7-b54e-6d24f689c700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Added the following directory to the PYTHONPATH: c:\\Users\\Abdul Rahman\\Desktop\\Air-Quality-App-team\\mlfs-book\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    \n",
    "# Read the API keys and configuration variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f430c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "import hopsworks\n",
    "import json\n",
    "from mlfs.airquality import util\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcfd27c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 11, 12, 16, 2, 59, 233528)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.datetime.now() - datetime.timedelta(0)\n",
    "tomorrow = today + datetime.timedelta(days = 1)\n",
    "today"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e91e99d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74a2c243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-12 16:03:01,789 INFO: Initializing external client\n",
      "2025-11-12 16:03:01,790 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-11-12 16:03:02,943 WARNING: UserWarning: The installed hopsworks client version 4.4.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-12 16:03:06,103 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1271977\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(engine=\"python\", project=\"air_quality_prediction\")\n",
    "fs = project.get_feature_store() \n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "# location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "# location = json.loads(location_str)\n",
    "# country=location['country']\n",
    "# city=location['city']\n",
    "# street=location['street']\n",
    "\n",
    "sensor_secret_names = [\n",
    "    \"SENSOR_LOCATION_bankgatan_JSON\",\n",
    "    \"SENSOR_LOCATION_linakersvagen_JSON\",\n",
    "    \"SENSOR_LOCATION_trollebergsvagen_JSON\",\n",
    "]\n",
    "\n",
    "sensors = {}\n",
    "for name in sensor_secret_names:\n",
    "    data = json.loads(secrets.get_secret(name).value)\n",
    "    sensors[data[\"street\"]] = {\n",
    "        \"country\":   data[\"country\"],\n",
    "        \"city\":      data[\"city\"],\n",
    "        \"street\":    data[\"street\"],\n",
    "        \"latitude\":  data[\"latitude\"],\n",
    "        \"longitude\": data[\"longitude\"],\n",
    "        \"aqicn_url\": data[\"aqicn_url\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb1c037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.75s) \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=1\n",
    ")\n",
    "\n",
    "air_quality_df_full = air_quality_fg.read()\n",
    "streets_sorted = sorted(air_quality_df_full['street'].dropna().unique().tolist())\n",
    "street_encoder = LabelEncoder().fit(streets_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cead441",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">ü™ù Download the model from Model Registry</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d70a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-12 16:03:20,731 INFO: Initializing for batch retrieval of feature vectors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72b57a9ae2845fc9a74c9636c7824fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/451818 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4760e23150bb4a049bd5df6c6f6f912d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/121037 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9488dde8f4004201bcc7657095679f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/86757 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717990f614984dd4bc00c0dce99041ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/125779 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 4 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8f3d9896954d1a816ec6d62ca9bd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/21612 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 5 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "mr = project.get_model_registry()\n",
    "\n",
    "retrieved_model = mr.get_model(\n",
    "    name=\"air_quality_xgboost_model\",\n",
    "    version=2,\n",
    ")\n",
    "\n",
    "fv = retrieved_model.get_feature_view()\n",
    "\n",
    "# Download the saved model artifacts to a local directory\n",
    "saved_model_dir = retrieved_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6cf6c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=&#x27;8.042732E0&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;int&#x27;],\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=&#x27;8.042732E0&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;int&#x27;],\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score='8.042732E0', booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=['float', 'float', 'float', 'float', 'int'],\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the XGBoost regressor model and label encoder from the saved model directory\n",
    "# retrieved_xgboost_model = joblib.load(saved_model_dir + \"/xgboost_regressor.pkl\")\n",
    "retrieved_xgboost_model = XGBRegressor()\n",
    "\n",
    "retrieved_xgboost_model.load_model(saved_model_dir + \"/model.json\")\n",
    "\n",
    "# Displaying the retrieved XGBoost regressor model\n",
    "retrieved_xgboost_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ad941a",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚ú® Get Weather Forecast Features with Feature View   </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaacae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e4491",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">ü§ñ Making the predictions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cebeaa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x1b22a358610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "today = datetime.datetime.now() \n",
    "\n",
    "monitor_fg = fs.get_or_create_feature_group(\n",
    "    name='aq_predictions',\n",
    "    description='Air Quality prediction monitoring',\n",
    "    version=1,\n",
    "    primary_key=['city','street','date','days_before_forecast_day'],\n",
    "    event_time=\"date\",\n",
    ")\n",
    "\n",
    "monitor_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bfb9f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.70s) \n",
      "2025-11-12 16:04:01,186 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n",
      "2025-11-12 16:04:01,187 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 6/6 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: aq_predictions_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1271977/jobs/named/aq_predictions_1_offline_fg_materialization/executions\n",
      "2025-11-12 16:04:16,637 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-12 16:04:19,812 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-12 16:05:52,237 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-12 16:05:52,389 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-12 16:06:04,256 INFO: Execution finished successfully.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.02s) \n",
      "2025-11-12 16:06:06,130 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n",
      "2025-11-12 16:06:06,132 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 6/6 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: aq_predictions_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1271977/jobs/named/aq_predictions_1_offline_fg_materialization/executions\n",
      "2025-11-12 16:06:21,390 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-12 16:06:27,774 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-12 16:08:19,338 INFO: Waiting for execution to finish. Current state: SUCCEEDING. Final status: UNDEFINED\n",
      "2025-11-12 16:08:28,894 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-12 16:08:29,046 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-12 16:08:37,599 INFO: Execution finished successfully.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.98s) \n",
      "2025-11-12 16:08:38,969 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n",
      "2025-11-12 16:08:38,970 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 6/6 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: aq_predictions_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1271977/jobs/named/aq_predictions_1_offline_fg_materialization/executions\n",
      "2025-11-12 16:09:11,405 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-12 16:09:14,591 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-12 16:11:12,577 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-12 16:11:12,723 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-12 16:11:21,261 INFO: Execution finished successfully.\n"
     ]
    }
   ],
   "source": [
    "all_preds_for_city = []  \n",
    "\n",
    "for street, meta in sensors.items():\n",
    "\n",
    "    batch_data = weather_fg.filter(weather_fg.date >= today).read().copy()\n",
    "    if batch_data.empty:\n",
    "        print(f\"[WARN] No weather rows for {street}; skipping.\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    batch_data['country'] = meta['country']\n",
    "    batch_data['city']    = meta['city']\n",
    "    batch_data['street']  = meta['street']\n",
    "\n",
    "    batch_data['date'] = pd.to_datetime(batch_data['date']).dt.tz_localize(None)\n",
    "    batch_data = batch_data.sort_values('date').reset_index(drop=True)\n",
    "    batch_data['days_before_forecast_day'] = ((batch_data['date'] - today).dt.days + 1)\n",
    "    batch_data = batch_data.query('days_before_forecast_day >= 1')\n",
    "\n",
    "    batch_data['street_encode'] = street_encoder.transform(batch_data['street']).astype('float32')\n",
    "\n",
    "\n",
    "    feature_cols_for_inference = [\n",
    "        'temperature_2m_mean',\n",
    "        'precipitation_sum',\n",
    "        'wind_speed_10m_max',\n",
    "        'wind_direction_10m_dominant',\n",
    "        'street_encode',\n",
    "    ]\n",
    "    batch_data['predicted_pm25'] = retrieved_xgboost_model.predict(\n",
    "        batch_data[feature_cols_for_inference]\n",
    "    )\n",
    "\n",
    "\n",
    "    monitor_fg.insert(batch_data.drop(columns=['street_encode']), wait=True)\n",
    "\n",
    "    all_preds_for_city.append(batch_data.drop(columns=['street_encode']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23e2b0a",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">ü§ñ Saving the predictions (for monitoring) to a Feature Group</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff10c12",
   "metadata": {},
   "source": [
    "### Create Forecast Graph\n",
    "Draw a graph of the predictions with dates as a PNG and save it to the github repo\n",
    "Show it on github pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c99085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "root_dir = str(Path().absolute())\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# this part is specific to me due to directory naming issues. \n",
    "def find_repo_root():\n",
    "    here = Path.cwd()\n",
    "    for p in [here, *here.parents]:\n",
    "        if (p / \"docs\").exists():\n",
    "            return p\n",
    "    return here  \n",
    "\n",
    "project_root = find_repo_root()\n",
    "\n",
    "img_dir = project_root / \"docs\" / \"air-quality\" / \"assets\" / \"img\"\n",
    "img_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "today_str = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n",
    "today_str = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "dataset_api = project.get_dataset_api()\n",
    "if not dataset_api.exists(\"Resources/airquality\"):\n",
    "    dataset_api.mkdir(\"Resources/airquality\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa2c1b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.37s) \n",
      "bankgatan rows: 6 nans: 0 dates: 2025-11-13 00:00:00 ‚Üí 2025-11-18 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6435e91872cb43d7a7e81511b2269431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading c:\\Users\\Abdul Rahman\\Desktop\\Air-Quality-App-team\\mlfs-book\\docs\\air-quality\\assets\\img\\lund_bankga‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b103fd35564350bca53ff9ba09cd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading c:\\Users\\Abdul Rahman\\Desktop\\Air-Quality-App-team\\mlfs-book\\docs\\air-quality\\assets\\img\\lund_bankga‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin√•kersv√§gen rows: 6 nans: 0 dates: 2025-11-13 00:00:00 ‚Üí 2025-11-18 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f5d3c6cf7e44cf9d54aad43a7ad803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading c:\\Users\\Abdul Rahman\\Desktop\\Air-Quality-App-team\\mlfs-book\\docs\\air-quality\\assets\\img\\lund_lin√•ke‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7e7cb29cfc475fa941d046c40daf6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading c:\\Users\\Abdul Rahman\\Desktop\\Air-Quality-App-team\\mlfs-book\\docs\\air-quality\\assets\\img\\lund_lin√•ke‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trollebergsv√§gen rows: 6 nans: 0 dates: 2025-11-13 00:00:00 ‚Üí 2025-11-18 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62082cfa7ba4d11923387320b6eab94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading c:\\Users\\Abdul Rahman\\Desktop\\Air-Quality-App-team\\mlfs-book\\docs\\air-quality\\assets\\img\\lund_trolle‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3477038268bf4f25bdde750654093131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading c:\\Users\\Abdul Rahman\\Desktop\\Air-Quality-App-team\\mlfs-book\\docs\\air-quality\\assets\\img\\lund_trolle‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are saved here: https://c.app.hopsworks.ai:443/p/1271977/settings/fb/path/Resources/airquality\n"
     ]
    }
   ],
   "source": [
    "city = next(iter(sensors.values()))['city']  # since all sensors are in the same city\n",
    "preds_1day_city = monitor_fg.filter(\n",
    "    (monitor_fg.city == city) &\n",
    "    (monitor_fg.days_before_forecast_day == 1)\n",
    ").read().copy()\n",
    "\n",
    "def _norm_dates(series):\n",
    "    s = pd.to_datetime(series, errors=\"coerce\")\n",
    "    try:\n",
    "        s = s.dt.tz_convert(None)   \n",
    "    except Exception:\n",
    "        pass\n",
    "    return s.dt.normalize()\n",
    "\n",
    "for street, meta in sensors.items():\n",
    "\n",
    "    preds_1day = preds_1day_city[preds_1day_city['street'] == street].copy()\n",
    "\n",
    "    outcomes = air_quality_df_full[\n",
    "        (air_quality_df_full['city'] == meta['city']) &\n",
    "        (air_quality_df_full['street'] == street)\n",
    "    ][['date', 'pm25']].copy()\n",
    "\n",
    "\n",
    "    try:\n",
    "        nday_df = next(df for df in all_preds_for_city if df['street'].iloc[0] == street)\n",
    "    except StopIteration:\n",
    "        print(f\"[WARN] No in-memory forecast DF found for street '{street}'. Skipping plots.\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    safe_city = str(meta['city']).replace(' ', '_').lower()\n",
    "    safe_street = str(street).replace(' ', '_').lower()\n",
    "\n",
    "    pred_file_path = str(img_dir / f\"{safe_city}_{safe_street}_pm25_forecast.png\")\n",
    "    hindcast_file_path = str(img_dir / f\"{safe_city}_{safe_street}_pm25_hindcast_1day.png\")\n",
    "\n",
    "\n",
    "    print(\n",
    "        street,\n",
    "        \"rows:\", len(nday_df),\n",
    "        \"nans:\", nday_df['predicted_pm25'].isna().sum() if 'predicted_pm25' in nday_df.columns else 'col-missing',\n",
    "        \"dates:\", nday_df['date'].min(), \"‚Üí\", nday_df['date'].max()\n",
    "    )\n",
    "    plt = util.plot_air_quality_forecast(meta['city'], street, nday_df, pred_file_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    if preds_1day.empty or outcomes.empty:\n",
    "        print(f\"[WARN] Empty preds_1day or outcomes for '{street}'. Skipping hindcast plot.\")\n",
    "    else:\n",
    "  \n",
    "        preds_1day['date'] = _norm_dates(preds_1day['date'])\n",
    "        outcomes['date']   = _norm_dates(outcomes['date'])\n",
    "\n",
    "        min_d, max_d = outcomes['date'].min(), outcomes['date'].max()\n",
    "        preds_1day = preds_1day[(preds_1day['date'] >= min_d) & (preds_1day['date'] <= max_d)].copy()\n",
    "\n",
    "        hindcast_df = (\n",
    "            preds_1day[['date', 'predicted_pm25']]\n",
    "            .merge(outcomes, on='date', how='inner')\n",
    "            .sort_values('date')\n",
    "        )\n",
    "\n",
    "        if hindcast_df.empty:\n",
    "            print(f\"[WARN] No overlapping dates for hindcast at '{street}'. Skipping hindcast plot.\")\n",
    "        else:\n",
    "            plt = util.plot_air_quality_forecast(\n",
    "                meta['city'], street, hindcast_df, hindcast=True, file_path=hindcast_file_path\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    hops_dir = f\"Resources/airquality/{safe_city}_{safe_street}_{today_str}\"\n",
    "    dataset_api.upload(pred_file_path, hops_dir, overwrite=True)\n",
    "    if Path(hindcast_file_path).exists():\n",
    "        dataset_api.upload(hindcast_file_path, hops_dir, overwrite=True)\n",
    "\n",
    "print(f\"The images are saved here: {project.get_url()}/settings/fb/path/Resources/airquality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb1552",
   "metadata": {},
   "source": [
    "### Plot the Hindcast comparing predicted with forecasted values (1-day prior forecast)\n",
    "\n",
    "__This graph will be empty to begin with - this is normal.__\n",
    "\n",
    "After a few days of predictions and observations, you will get data points in this graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf88a81-5a3e-43d7-a8a5-177e5c2b5387",
   "metadata": {},
   "source": [
    "### Upload the prediction and hindcast dashboards (png files) to Hopsworks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29eb549",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airq310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
